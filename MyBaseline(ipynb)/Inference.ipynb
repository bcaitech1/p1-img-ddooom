{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "affected-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from albumentations import *\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models as models\n",
    "from torchsummary import summary\n",
    "from efficientnet_pytorch import EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "scenic-nowhere",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define argumentation function\n",
    "def get_transforms(need=('train', 'val'), img_size=(512, 384), mean=(0.560, 0.524, 0.501), std=(0.233, 0.243, 0.246)):\n",
    "    transformations = {}\n",
    "    if 'train' in need:\n",
    "        transformations['train'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "            HorizontalFlip(p=0.5),\n",
    "            ShiftScaleRotate(p=0.7),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1, 0.3), contrast_limit=(-0.1, 0.3), p=0.5),\n",
    "            GaussNoise(p=0.7),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ], p=1.0)\n",
    "    if 'val' in need:\n",
    "        transformations['val'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ], p=1.0)\n",
    "    return transformations\n",
    "\n",
    "def tta_transforms(need=('origin', 'flip', 'rotate', 'contrast'), img_size=(512, 384), mean=(0.560, 0.524, 0.501), std=(0.233, 0.243, 0.246)):\n",
    "    transformations = {}\n",
    "    if 'origin' in need:\n",
    "        transformations['origin'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ], p=1.0)\n",
    "    if 'flip' in need:\n",
    "        transformations['flip'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "            HorizontalFlip(p=1.0),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ], p=1.0)\n",
    "    if 'rotate' in need:\n",
    "        transformations['rotate'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "            ShiftScaleRotate(p=1.0),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ], p=1.0)\n",
    "    if 'contrast' in need:\n",
    "        transformations['contrast'] = Compose([\n",
    "            Resize(img_size[0], img_size[1], p=1.0),\n",
    "            RandomBrightnessContrast(brightness_limit=(-0.1, 0.3), contrast_limit=(-0.1, 0.3), p=1.0),\n",
    "            Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ], p=1.0)\n",
    "    return transformations\n",
    "\n",
    "# define testdataset\n",
    "class TestDataset(Dataset):\n",
    "    def __init__(self, path, transform):\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image = Image.open(self.path[index])\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image=np.array(image))\n",
    "            \n",
    "        return image['image']\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "passing-comfort",
   "metadata": {},
   "source": [
    "# inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "portable-acting",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [02:46<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* inference, model save done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "title = 'effnetb3_celoss_nokfold_agefilter57'\n",
    "model_name = '07_0.646_0.632_0.947'  # ex) 14_0.212_0.926_0.200_0.933.\n",
    "\n",
    "\n",
    "model_path = f'models/{title}/{model_name}.pth'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_type = title.split('_')[0]\n",
    "if model_type == 'effnetb3':\n",
    "    model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=18)\n",
    "elif model_type == 'resnet50':\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(in_features=2048, out_features=18, bias=True)\n",
    "elif model_type == 'resnet101':\n",
    "    model = models.resnet101(pretrained=True)\n",
    "    model.fc = nn.Linear(in_features=2048, out_features=18, bias=True)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "\n",
    "# inference\n",
    "submission = pd.read_csv('input/data/eval/info.csv')\n",
    "test_img_dir = 'input/data/eval/images'\n",
    "\n",
    "test_path = [f'{test_img_dir}/{img_id}' for img_id in submission.ImageID]\n",
    "\n",
    "\n",
    "transform = get_transforms()\n",
    "test_dataset = TestDataset(test_path, transform['val'])\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size = 64,\n",
    "    shuffle = False\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "test_predictions = []\n",
    "for img in tqdm(test_loader):\n",
    "    with torch.no_grad():\n",
    "        img = img.to(device)\n",
    "        pred = model(img)\n",
    "        pred_class = torch.max(pred, 1)[1]\n",
    "        test_predictions.extend(list(pred_class.cpu().numpy()))\n",
    "\n",
    "submission['ans'] = test_predictions\n",
    "\n",
    "# save submission\n",
    "if not os.path.isdir('submissions'):\n",
    "    os.makedirs('submissions')\n",
    "\n",
    "if not os.path.isdir(f'submissions/{title}'):\n",
    "    os.makedirs(f'submissions/{title}')    \n",
    "    \n",
    "submission.to_csv(f'submissions/{title}/{model_name}.csv', index=False)\n",
    "print('* inference, model save done \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-finnish",
   "metadata": {},
   "source": [
    "# Inference for ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "overall-dallas",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_ensemble = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "historic-council",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [03:09<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [03:41<00:00,  1.12s/it]\n",
      "100%|██████████| 197/197 [04:30<00:00,  1.37s/it]\n",
      "100%|██████████| 197/197 [03:18<00:00,  1.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# ensemble inference\n",
    "titles = ['effnetb3_celoss_nokfold_agefilter',\n",
    "          'effnetb3_celoss_nokfold_agefilter_alltrain',\n",
    "          'resnet101_celoss_nokfold_agefilter',\n",
    "          'resnet50_celoss_nokfold_agefilter'\n",
    "         ]\n",
    "          \n",
    "loop_model = ['06_0.637_0.634_0.963',\n",
    "              '06_alltraining',\n",
    "              '03_0.624_0.612_0.935',\n",
    "              '06_0.630_0.630_0.949'\n",
    "             ]\n",
    "\n",
    "for title, m in zip(titles,loop_model):\n",
    "    \n",
    "    model_path = f'models/{title}/{m}.pth'\n",
    "\n",
    "    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    model_name = title.split('_')[0]\n",
    "    if model_name == 'effnetb3':\n",
    "        model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=18)\n",
    "    elif model_name == 'resnet50':\n",
    "        model = models.resnet50(pretrained=True)\n",
    "        model.fc = nn.Linear(in_features=2048, out_features=18, bias=True)\n",
    "    elif model_name == 'resnet101':\n",
    "        model = models.resnet101(pretrained=True)\n",
    "        model.fc = nn.Linear(in_features=2048, out_features=18, bias=True)\n",
    "\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.to(device)\n",
    "\n",
    "    # inference\n",
    "    submission = pd.read_csv('input/data/eval/info.csv')\n",
    "    test_img_dir = 'input/data/eval/images'\n",
    "\n",
    "    test_path = [f'{test_img_dir}/{img_id}' for img_id in submission.ImageID]\n",
    "\n",
    "\n",
    "    transform = get_transforms()\n",
    "    test_dataset = TestDataset(test_path, transform['val'])\n",
    "\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size = 64,\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    test_percentage = []\n",
    "#     test_predictions = []\n",
    "    for img in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            img = img.to(device)\n",
    "            pred = model(img)\n",
    "            pred_class = torch.max(pred, 1)[1]\n",
    "            test_percentage.extend(list(pred.cpu().numpy()))\n",
    "#             test_predictions.extend(list(pred_class.cpu().numpy()))\n",
    "    \n",
    "    fold_ensemble[f'{title}/{m}'] = test_percentage\n",
    "#     submission['ans'] = test_predictions\n",
    "\n",
    "#     # save submission\n",
    "#     if not os.path.isdir('submissions'):\n",
    "#         os.makedirs('submissions')\n",
    "\n",
    "#     if not os.path.isdir(f'submissions/{title}'):\n",
    "#         os.makedirs(f'submissions/{title}')    \n",
    "\n",
    "#     submission.to_csv(f'submissions/{title}/{i}.csv', index=False)\n",
    "#     print('* inference, model save done \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "chief-bernard",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* final top models\n",
      "effnetb3_celoss_nokfold/05_0.595_0.592_0.965\n",
      "effnetb3_celoss_nokfold/12_0.602_0.599_0.979\n",
      "effnetb3_celoss_nokfold/14_0.604_0.599_0.964\n",
      "effnetb3_celoss_nokfold/03_alltraining\n",
      "effnetb3_celoss_nokfold/02_alltraining\n",
      "resnet50_notune/25_0.071_0.975_0.064_0.981\n",
      "resnet50_notune/39_0.053_0.983_0.050_0.989\n",
      "resnet50_focalloss_nokfold/17_0.579_0.576_0.977\n",
      "resnet101_focalloss_nokfold/12_0.563_0.579_0.983\n"
     ]
    }
   ],
   "source": [
    "print('* final top models')\n",
    "for m in fold_ensemble.keys():\n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "suspected-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble submission save\n",
    "ensemble_models = fold_ensemble.keys()\n",
    "sum_pred = np.zeros((12600,18))\n",
    "for model in ensemble_models:\n",
    "    sum_pred += np.array(fold_ensemble[model])\n",
    "\n",
    "submission['ans'] = np.argmax(sum_pred,axis=1)\n",
    "\n",
    "if not os.path.isdir('submissions/final_ensemble'):\n",
    "    os.mkdir('submissions/final_ensemble')\n",
    "submission.to_csv(f'submissions/final_ensemble/all_ensemble_agefilter58.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surgical-indicator",
   "metadata": {},
   "source": [
    "# Inference for TTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "found-genius",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "graphic-focus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/197 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [02:34<00:00,  1.28it/s]\n",
      "100%|██████████| 197/197 [02:50<00:00,  1.15it/s]\n",
      "100%|██████████| 197/197 [03:24<00:00,  1.04s/it]\n",
      "100%|██████████| 197/197 [02:56<00:00,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* inference, model save done \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "title = 'effnetb3_celoss_nokfold_agefilter58_aug'\n",
    "model_name = '10_0.610_0.618_0.969'  # ex) 14_0.212_0.926_0.200_0.933.\n",
    "\n",
    "\n",
    "model_path = f'models/{title}/{model_name}.pth'\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_type = title.split('_')[0]\n",
    "if model_type == 'effnetb3':\n",
    "    model = EfficientNet.from_pretrained('efficientnet-b3', num_classes=18)\n",
    "elif model_type == 'resnet50':\n",
    "    model = models.resnet50(pretrained=True)\n",
    "    model.fc = nn.Linear(in_features=2048, out_features=18, bias=True)\n",
    "elif model_type == 'resnet101':\n",
    "    model = models.resnet101(pretrained=True)\n",
    "    model.fc = nn.Linear(in_features=2048, out_features=18, bias=True)\n",
    "\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(device)\n",
    "\n",
    "# inference\n",
    "submission = pd.read_csv('input/data/eval/info.csv')\n",
    "test_img_dir = 'input/data/eval/images'\n",
    "\n",
    "test_path = [f'{test_img_dir}/{img_id}' for img_id in submission.ImageID]\n",
    "\n",
    "\n",
    "transform = tta_transforms()\n",
    "test_datasets = [TestDataset(test_path, transform['origin']),\n",
    "                 TestDataset(test_path, transform['flip']),\n",
    "                 TestDataset(test_path, transform['rotate']),\n",
    "                 TestDataset(test_path, transform['contrast'])]\n",
    "\n",
    "tta_ensemble = []\n",
    "for test_dataset in test_datasets:\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size = 64,\n",
    "        shuffle = False\n",
    "    )\n",
    "\n",
    "    model.eval()\n",
    "    test_percentage = []\n",
    "    for img in tqdm(test_loader):\n",
    "        with torch.no_grad():\n",
    "            img = img.to(device)\n",
    "            pred = model(img)\n",
    "            test_percentage.extend(list(pred.cpu().numpy()))\n",
    "\n",
    "    tta_ensemble.append(test_percentage)\n",
    "\n",
    "# save submission\n",
    "if not os.path.isdir('submissions'):\n",
    "    os.makedirs('submissions')\n",
    "\n",
    "if not os.path.isdir(f'submissions/{title}'):\n",
    "    os.makedirs(f'submissions/{title}')    \n",
    "\n",
    "sum_pred = np.zeros((12600,18))\n",
    "for pred in tta_ensemble:\n",
    "    sum_pred += np.array(pred)\n",
    "\n",
    "submission['ans'] = np.argmax(sum_pred,axis=1)\n",
    "    \n",
    "submission.to_csv(f'submissions/{title}/{model_name}_tta.csv', index=False)\n",
    "print('* inference, model save done \\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
